# Workflow to generate two-dimensional representations and visualisations of read k-mer composition

## Software requirements
- Install dependencies from source:
  - <a href="https://github.com/CobiontID/kmer-counter">kmer-counter</a> (required)
  - <a href="https://github.com/CobiontID/unique-kmer-counts">unique-kmer-counter</a>
  - <a href="https://github.com/CobiontID/fastk-medians">fastk-medians</a> (install `FastK` and `ProfMedianAll`)
  - <a href="https://github.com/richarddurbin/hexamer">Hexamer</a> (you will need `cds.worm.hex`, which can be generated by running `hextable -o worm.hex worm.coding`. The input file `worm.coding` contains coding sequences).

- Set up a Conda environment according with <a href="https://github.com/CobiontID/read_VAE/blob/main/env_kmerviz.yaml">this</a> configuration (see <a href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file">here</a> for instructions).
- You will also need `vae.py`, `category_labels_from_cont.py`, and `vae_draw.py` from this repository. 

### Running the Snakemake pipeline

The included example set-up assumes that the script will be run on an LSF cluster. For instructions how to run the steps individually, see [below](###-How-to-run-steps-individually-on-the-commandline:).

- Set up the configuration in <a href="https://github.com/CobiontID/read_VAE/blob/main/read_tools/config.yml">config.yml</a>
  - Set up the sample to be run: 
     - `sample_id`: The sample identifier (used to name output files)
     - `species_name`: The full species name (this field is included for record-keeping purposes)
     - `read_file`: Path to the fasta file containing the reads to be analysed.
     - `fastk_tab`: Path to FastK .ktab file. Optional. If provided, FastK will profile the reads against the existing table. If not using, set to `None`. The default k-mer length is k = 31 as of Feb 2022.
     
   - Base configuration:
     - `user_group`: User group to be used for LSF
     - `tetra_count_path`: Path to the k-mer counter executable
     - `fastk_path`: Base path to FastK and ProfMedianAll executables
     - `un_count_path`: Path to unique k-mer counter executable
     - `hexamer_path`: Path to hexsum executable (for estimating coding density)
     - `vae_path`: Path to Variational Autencoder-based k-mer decomposition script
     - `draw_vae_path`: Path to script for plotting decomposed read k-mers
     - `cat_labeller_path`: Path to script for generating bins for reads from a continuous vector
     - `hextable_path`: Path to reference table for Hexamer/Hexsum
     - `conda_tf`: The conda environment used for the decomposition and visualisation steps. Required packages are specified in in <a href="https://github.com/CobiontID/kmer_decomposition/blob/main/env_kmerviz.yaml">env_kmerviz.yaml</a>.

#### Run
In a conda environment with <a href="https://snakemake.readthedocs.io/en/stable/">Snakemake</a> installed, run `Snakemake`. Depending on the input data, the memory requirements may need to be adjusted in the Snakefile.

### How to run steps individually on the commandline:

1. Count canonicalized tetranucleotides:
```
kmer-counter --file reads_sampleid.fa.gz --ids sampleid.reads.ids.txt --klength 4 --out sampleid.reads.tetra.collapsed.npy
```

2. Count unique 8-mers per base:
```
unique-kmers --klength 8 --file reads_sampleid.fa.gz --out sampleid.8mer.txt
```

3. Calculate estimated coding density with Hexamer (Piping is only necessary if the input fasta file is gzip-ed):
```
zcat reads_sampleid.fa.gz | hexamer -T 20 -S /software/hexamer/cds.worm.hex - | awk '{ print $3/$2 }' > sampleid.reads.hexsum
```

4. Get median number of times each k-mer of size 31 in each read occurs across the dataset:
```
mkdir -p ./fastk/profile/
cp -n reads_sampleid.fa.gz ./fastk/profile/reads_sampleid.fa.gz
FastK -k31 -T8 -M14 -p ./fastk/profile/reads_sampleid.fa.gz
ProfMedianAll ./fastk/profile/*prof > sampleid.median_31mer.txt
# Remove intermediate files
rm -R ./fastk
```

5. Run the VAE:
```
conda activate /software/conda/kmerviz
outdir=./vae/sampleid/
mkdir -p $outdir
python ./VAE/vae.py --countfile sampleid.reads.tetra.collapsed.npy --fignames sampleid --kl 0.0025 --epochs 15 --outdir ${outdir}
```

6. Generate colour-coded plots. First, assign labels based on k-mer statistics:

```
python ./plotting_tools/category_labels_from_cont.py --feature sampleid.reads.hexsum --labelled hexsum.binned.sampleid --n 10
python ./plotting_tools/category_labels_from_cont.py --feature sampleid.median_31mer.txt --labelled 31mer.binned.sampleid --n 10
python ./plotting_tools/category_labels_from_cont.py --feature sampleid.8mer.txt --labelled 8mer.binned.sampleid --n 10
```

7. Draw the plots:
```
python ./VAE/vae_draw.py --zfile ${outdir}/sampleid.vae.out.2d.0 --outdir ${outdir}/ --fignames sampleid_31mer --labels 31mer.binned.sampleid --edges 31mer.binned.sampleid.edges --legend_y_label "Median 31-mer count"
python ./VAE/vae_draw.py --zfile ${outdir}/sampleid.vae.out.2d.0 --outdir ${outdir}/ --fignames sampleid_hexamer --labels hexsum.binned.sampleid --edges hexsum.binned.sampleid.edges --legend_y_label "Hexamer"
python ./VAE/vae_draw.py --zfile ${outdir}/sampleid.vae.out.2d.0 --outdir ${outdir}/ --fignames sampleid_8mer --labels 8mer.binned.sampleid --edges 8mer.binned.sampleid.edges --legend_y_label "Unique 8-mers/base"
```

## Notes
### Very large data sets
For an initial glance at a dataset, switching off the CB correction, increasing the batch size, and reducing the number of epochs can speed up VAE training (see [here](https://github.com/CobiontID/read_VAE/tree/main/read_tools/VAE)).

The default workflow is set up so that the entire k-mer count table is loaded into memory while training the VAE. Given a large number of sequences, this table may be larger than the specified defaults and/or available RAM. In this case, it may be useful to downsample the dataset prior to training. Alternatively, it is possible to split the input data into smaller pre-processed batches (this code is currently not production-ready).

### Short reads
Short read datasets with many sequences can lead to computational bottlenecks, as noted above. In addition, shorter sequences will inherently behave differently. Consider reducing the threshold `-T`in `hexamer`, as the default will likely result in a very small number of sequences being assigned values greater than zero. They will also produce more sparse k-mer count tables. Reducing `k` when counting unique k-mers may therefore be advantageous.
